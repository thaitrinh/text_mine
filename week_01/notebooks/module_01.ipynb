{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic text commands "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Ethics are built right into the ideas and objectives of the United Nations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of the string\n",
    "len(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "['Ethics', 'are', 'built', 'right', 'into', 'the', 'ideas', 'and', 'objectives', 'of', 'the', 'United', 'Nations']\n"
     ]
    }
   ],
   "source": [
    "# how many tokens in the string\n",
    "token_list = text1.split()   # or text1.split(\" \") \n",
    "print(len(token_list))\n",
    "# print all tokens\n",
    "print(token_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Long words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ethics', 'built', 'right', 'into', 'ideas', 'objectives', 'United', 'Nations']\n"
     ]
    }
   ],
   "source": [
    "# words that have more than 3 letters\n",
    "list3lett = [w for w in token_list if len(w) > 3]\n",
    "print(list3lett)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capitalized words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ethics', 'United', 'Nations']\n"
     ]
    }
   ],
   "source": [
    "cap = [w for w in token_list if w.istitle()]\n",
    "print(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Words ends with 's'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ethics', 'ideas', 'objectives', 'Nations']\n"
     ]
    }
   ],
   "source": [
    "s_end = [w for w in token_list if w.endswith('s')]\n",
    "print(s_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'be', 'not', 'to', 'To', 'or'}\n",
      "{'be', 'not', 'or', 'to'}\n"
     ]
    }
   ],
   "source": [
    "# key sensitive\n",
    "text3 = 'To be or not to be'\n",
    "key_sen = set([w for w in text3.split()])\n",
    "print(key_sen)\n",
    "# ignore captialized character\n",
    "no_key_sen = set([w.lower() for w in text3.split()])\n",
    "print(no_key_sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check upper, lower case, capitalized first letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# check if all characters are upper case\n",
    "t = 'THAI'\n",
    "print(t.isupper())\n",
    "# check if all character are lower case\n",
    "t = 'thai'\n",
    "print(t.islower())\n",
    "# check if the first letter is capitalized but others are lower case\n",
    "t = 'Thai'\n",
    "print(t.islower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check alpha, digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# check if string contains only letters, no space or digit\n",
    "s = \"this\"  # No space & digit in this string\n",
    "print(s.isalpha())\n",
    "\n",
    "s = \"this is Thai\"\n",
    "print(s.isalpha())\n",
    "\n",
    "# check if string contains only digits\n",
    "s = \"123456\"  # Only digit in this string\n",
    "print(s.isdigit())\n",
    "\n",
    "s = \"123 456\"\n",
    "print(s.isdigit())\n",
    "\n",
    "# check if string contains only letter and digits\n",
    "s = \"this2009\"  # No space in this string\n",
    "print(s.isalnum())\n",
    "\n",
    "s = \"this_2009\"\n",
    "print(s.isalnum())\n",
    "\n",
    "s = \"this 2009\"\n",
    "print(s.isalnum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upper, lower, title strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THAI DEP TRAI QUA\n",
      "Thai Dep Trai Qua\n",
      "thai dep trai qua\n",
      "THAI DEP TRAI QUA\n",
      "Thai Dep Trai Qua\n"
     ]
    }
   ],
   "source": [
    "# make upper, lower, title\n",
    "s = 'thai dep trai qua'\n",
    "print(s.upper())\n",
    "print(s.title())\n",
    "s = 'Thai dep TRAI quA'\n",
    "print(s.lower())\n",
    "print(s.upper())\n",
    "print(s.title())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thai\n",
      "dep\n",
      "trai\n",
      "qua\n",
      "['thai', 'dep', 'trai', 'qua']\n"
     ]
    }
   ],
   "source": [
    "# split lines\n",
    "s = 'thai\\ndep\\ntrai\\nqua'\n",
    "print(s)\n",
    "print(s.splitlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thaideptraiqua\n",
      "thai dep trai qua\n"
     ]
    }
   ],
   "source": [
    "# join\n",
    "s1 = ''.join(s.splitlines())\n",
    "s2 = ' '.join(s.splitlines())\n",
    "print(s1)\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean using strip, lstrip, rstrip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Thai dep trai qua   \n",
      "Thai dep trai quahaha\n"
     ]
    }
   ],
   "source": [
    "# strip: remove space and tab in the front AND in the end\n",
    "s = \"   Thai dep trai qua   \"\n",
    "print(s)\n",
    "print(s.strip() + 'haha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find string using s.find(t), s.rfind(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "16\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "s = \"  thai dep trai thai thong minh Thai tai hoa\"\n",
    "# show the first index of 'thai' in the string s, case sensitive, if not found return -1\n",
    "print(s.find('thai'))\n",
    "# show the last index of 'thai' (searching from the right side)\n",
    "print(s.rfind('thai'))\n",
    "# case sensitive\n",
    "print(s.find('Thai'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thwas was string example....wow!!! thwas was really string\n",
      "thwas was string example....wow!!! thwas is really string\n"
     ]
    }
   ],
   "source": [
    "s = \"this is string example....wow!!! this is really string\"\n",
    "print(s.replace(\"is\", \"was\"))\n",
    "print(s.replace(\"is\", \"was\", 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split characters in a word/string ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t', 'h', 'a', 'i', 'd', 'e', 'p', 't', 'r', 'a', 'i']\n",
      "['t', 'h', 'a', 'i', 'd', 'e', 'p', 't', 'r', 'a', 'i']\n",
      "['t', 'h', 'a', 'i', ' ', 'd', 'e', 'p', ' ', 't', 'r', 'a', 'i']\n"
     ]
    }
   ],
   "source": [
    "s = 'thaideptrai'\n",
    "allchars = list(s)\n",
    "print(allchars)\n",
    "# or we can use list comprehensive\n",
    "allchars = [c for c in s]\n",
    "print(allchars)\n",
    "# how about string? we will get also spaces!\n",
    "s = 'thai dep trai'\n",
    "print(list(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling larger text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thai dep trai qua\n",
      "\n",
      "thai dep trai qua\n",
      "thai lai con thong minh nua\n",
      "thai cham chi lam viec\n",
      "thai kiem duoc nhieu tien\n",
      "thai thich di du lich\n",
      "\n",
      "['thai dep trai qua', 'thai lai con thong minh nua', 'thai cham chi lam viec', 'thai kiem duoc nhieu tien', 'thai thich di du lich']\n",
      "['thai dep trai qua\\n', 'thai lai con thong minh nua\\n', 'thai cham chi lam viec\\n', 'thai kiem duoc nhieu tien\\n', 'thai thich di du lich\\n']\n"
     ]
    }
   ],
   "source": [
    "# read the first line\n",
    "with open('example_text.txt') as f:\n",
    "    l = f.readline()\n",
    "    print(l)\n",
    "    # comeback to the very first position\n",
    "    f.seek(0)\n",
    "    # read the whole content\n",
    "    content = f.read()\n",
    "    print(content)\n",
    "    # split into separate lines\n",
    "    all_lines = content.splitlines()\n",
    "    print(all_lines)\n",
    "    # this way will return new line character\n",
    "    f.seek(0)\n",
    "    a = f.readlines()\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular expressions\n",
    "\n",
    "This is helpful for working with text with special characters, like twitter, where a lot of # or @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#regex', '#pandas', '#python']\n"
     ]
    }
   ],
   "source": [
    "# first method based on previous knowledge\n",
    "tweet = \"@nltk Text analysis is awesome! #regex #pandas #python\"\n",
    "ht = [x for x in tweet.split() if '#' in x]\n",
    "print(ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@UN', '@UN_Women', '\"Ethics', 'are', 'built', 'right', 'into', 'the', 'ideals', 'and', 'objectives', 'of', 'the', 'United', 'Nations\"', '#UNSG', '@', 'NY', 'Society', 'for', 'Ethical', 'Culture', 'bit.ly/2guVelr']\n",
      "['@UN', '@UN_Women', '\"Ethics', 'are', 'built', 'right', 'into', 'the', 'ideals', 'and', 'objectives', 'of', 'the', 'United', 'Nations\"', '#UNSG', '@', 'NY', 'Society', 'for', 'Ethical', 'Culture', 'bit.ly/2guVelr']\n"
     ]
    }
   ],
   "source": [
    "text7 = '@UN @UN_Women \"Ethics are built right into the ideals and objectives of the United Nations\" \\\n",
    "#UNSG @ NY Society for Ethical Culture bit.ly/2guVelr'\n",
    "# split the text into words\n",
    "text8 = text7.split(' ')\n",
    "print(text8)\n",
    "# or just () would do the same job\n",
    "text8 = text7.split()\n",
    "print(text8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "We can use regular expressions to help us with more complex parsing. \n",
    "\n",
    "For example `'@[A-Za-z0-9_]+'` will return all words that: \n",
    "* start with `'@'` and are followed by at least one: \n",
    "* capital letter (`'A-Z'`)\n",
    "* lowercase letter (`'a-z'`) \n",
    "* number (`'0-9'`)\n",
    "* or underscore (`'_'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@UN', '@UN_Women']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "atlist = [w for w in text8 if re.search('@[A-Za-z0-9]+', w)]\n",
    "# the plus sign means that the structure inside the square bracket should appear at least once\n",
    "# the structure inside the bracket means: a capital letter OR a lower case letter OR underscore\n",
    "print(atlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Some popular search patterns__\n",
    " * . matches any character except the new line character\n",
    " * ^ means start of the string\n",
    " * $ end of the string\n",
    " * [ ] match one of the character insde the square bracket (see example above)\n",
    " * [a-z] match one of the letter from a-z (lower case character)\n",
    " * [^abc] match character that is not a or b or c\n",
    " * a|b match either a or b, where a and b are string\n",
    " * () scoping for operators: Matches whatever regular expression is inside the parentheses, and indicates the start and end of a group; the contents of a group can be retrieved after a match has been performed\n",
    " https://docs.python.org/3.4/library/re.html\n",
    " * \\ escape character for special character like \\t \\n \\b\n",
    " * \\b matches word boundary: r'\\bfoo\\b' matches 'foo', 'foo.', '(foo)', 'bar foo baz' but not 'foobar' or 'foo3'\n",
    " * \\d matches any digit (0-9)\n",
    " * \\D any non-digit = [^0-9]\n",
    " * \\s any white space\n",
    " * \\S any non white space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@UN', '@UN_Women', '\"Ethics', 'are', 'built', 'right', 'into', 'the', 'ideals', 'and', 'objectives', 'of', 'the', 'United', 'Nations\"', '#UNSG', '@', 'NY', 'Society', 'for', 'Ethical', 'Culture', 'bit.ly/2guVelr', 'dsf23df4']\n",
      "['@UN', '@UN_Women', '\"Ethics', 'are', 'built', 'right', 'into', 'the', 'ideals', 'and', 'objectives', 'of', 'the', 'United', 'Nations\"', '#UNSG', '@', 'NY', 'Society', 'for', 'Ethical', 'Culture', 'bit.ly/2guVelr', 'dsf23df4']\n",
      "['@UN', '@UN_Women', '@']\n",
      "['are']\n",
      "['are', 'and']\n",
      "['\"Ethics', 'ideals', 'objectives']\n",
      "['\"Ethics', 'objectives']\n",
      "['bit.ly/2guVelr', 'dsf23df4', 'dsf23df4']\n",
      "['bit.ly/2guVelr']\n"
     ]
    }
   ],
   "source": [
    "l = [w for w in text8 if re.search('.', w)]\n",
    "print(l)\n",
    "# find all start of string/line. In this case each string is a single word, so start of string is also the same word\n",
    "l = [w for w in text8 if re.search('^', w)]\n",
    "print(l)\n",
    "\n",
    "# find all string start with @\n",
    "l = [w for w in text8 if re.search('^@', w)]\n",
    "print(l)\n",
    "\n",
    "# find all string start with ar\n",
    "l = [w for w in text8 if re.search('^ar', w)]\n",
    "print(l)\n",
    "\n",
    "# find all string start with ar or an\n",
    "l = [w for w in text8 if re.search('^a[r|n]', w)]\n",
    "print(l)\n",
    "\n",
    "# find all string end with s\n",
    "l = [w for w in text8 if re.search('s$', w)]\n",
    "print(l)\n",
    "\n",
    "# find all string end with cs or es\n",
    "l = [w for w in text8 if re.search('[c|e]s$', w)]\n",
    "print(l)\n",
    "\n",
    "text9 = text8.append('dsf23df4')\n",
    "# find any string which contain digit\n",
    "l = [w for w in text8 if re.search('\\d', w)]\n",
    "print(l)\n",
    "# find strings which contain only one digit\n",
    "l = [w for w in text8 if re.search('^\\D*\\d\\D*$', w)]\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object; span=(14, 34), match='[cus_Y4o9qMEZAugtnW]'>\n",
      "cus_Y4o9qMEZAugtnW\n"
     ]
    }
   ],
   "source": [
    "s = \"alpha.Customer[cus_Y4o9qMEZAugtnW] ...\"\n",
    "m = re.search(r\"\\[([A-Za-z0-9_]+)\\]\", s)\n",
    "print(m)\n",
    "print(m.group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * \\[ matches a literal [ character\n",
    " * ( begins a new group\n",
    " * [A-Za-z0-9_] is a character set matching any letter (capital or lower case), digit or underscore\n",
    " * + matches the preceding element (the character set) one or more times.\n",
    " * ) ends the group\n",
    " * \\] matches a literal ] character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repetition\n",
    "\n",
    " * * match 0 or many times\n",
    " * + match 1 or more than 1 times\n",
    " * ? match 0 or 1 time\n",
    " * {n} match exactly n times\n",
    " * {,n} match at most n times\n",
    " * {n,} match at least n times\n",
    " * {m,n} match at least m times and at most n times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding specific characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['o', 'u', 'a', 'a', 'o', 'u', 'o', 'u']\n",
      "['g', 'd', 'g']\n"
     ]
    }
   ],
   "source": [
    "text12 = \"ouagadougou\"\n",
    "print(re.findall(r'[aeiou]', text12))\n",
    "print(re.findall(r'[^aeiou]', text12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply to search for date string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['23-10', '23/10', '23/10', '10/23']\n",
      "['23-10-2006', '23/10/2006', '23/10/06', '10/23/2006']\n",
      "['23-10-2006', '23/10/2006', '23/10/06', '10/23/2006']\n"
     ]
    }
   ],
   "source": [
    "date_str = \"23-10-2006\\n23/10/2006\\n23/10/06\\n10/23/2006\\n23 Oct 2006\\n23 October 2006\\nOct 23, 2006\\nOctober 23, 2006\"\n",
    "\n",
    "# just day and month\n",
    "exp = r\"\\d{2}[-|/]\\d{2}\"\n",
    "# day, month and year\n",
    "print(re.findall(exp, date_str))\n",
    "# day month year could be 2 digits\n",
    "exp = r\"\\d{2}[-|/]\\d{2}[-/]\\d{2,4}\"\n",
    "print(re.findall(exp, date_str))\n",
    "# day month could be 1 or 2 digits year could be 2 digits\n",
    "exp = r\"\\d{1,2}[-|/]\\d{1,2}[-/]\\d{2,4}\"\n",
    "print(re.findall(exp, date_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Oct']\n",
      "['23 Oct 2006']\n",
      "['23 Oct 2006', '23 October 2006']\n",
      "***************\n",
      "['23 Oct 2006', '23 October 2006', 'Oct 23, 2006', 'October 23, 2006']\n"
     ]
    }
   ],
   "source": [
    "date_str = \"23-10-2006\\n23/10/2006\\n23/10/06\\n10/23/2006\\n23 Oct 2006\\n23 October 2006\\nOct 23, 2006\\nOctober 23, 2006\"\n",
    "\n",
    "# the parentheses here says: I want to pull out only the stuff which matches the group inside\n",
    "exp = r'\\d{2} (Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{2,4}'\n",
    "print(re.findall(exp, date_str))\n",
    "# the trick to get all text is adding ?:\n",
    "exp = r'\\d{2} (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{2,4}'\n",
    "print(re.findall(exp, date_str))\n",
    "# how about date with whole month text\n",
    "exp = r'\\d{2} (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* \\d{2,4}'\n",
    "print(re.findall(exp, date_str))\n",
    "print('***************')\n",
    "# date can be at the beginning or after month\n",
    "exp = r'(?:\\d{2} )?(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* (?:\\d{2}, )?\\d{2,4}'\n",
    "print(re.findall(exp, date_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with text in pandas***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider an example of data frame of text as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday: The doctor's appointment is at 2:45pm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuesday: The dentist's appointment is at 11:30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wednesday: At 7:00pm, there is a basketball game!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thursday: Be back home by 11:15 pm at the latest.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friday: Take the train at 08:10 am, arrive at ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0     Monday: The doctor's appointment is at 2:45pm.\n",
       "1  Tuesday: The dentist's appointment is at 11:30...\n",
       "2  Wednesday: At 7:00pm, there is a basketball game!\n",
       "3  Thursday: Be back home by 11:15 pm at the latest.\n",
       "4  Friday: Take the train at 08:10 am, arrive at ..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "time_sentences = [\"Monday: The doctor's appointment is at 2:45pm.\", \n",
    "                  \"Tuesday: The dentist's appointment is at 11:30 am.\",\n",
    "                  \"Wednesday: At 7:00pm, there is a basketball game!\",\n",
    "                  \"Thursday: Be back home by 11:15 pm at the latest.\",\n",
    "                  \"Friday: Take the train at 08:10 am, arrive at 09:00am.\"]\n",
    "\n",
    "df = pd.DataFrame(time_sentences, columns=['text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    46\n",
      "1    50\n",
      "2    49\n",
      "3    49\n",
      "4    54\n",
      "Name: text, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# get length of text of each row\n",
    "print(df['text'].str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     7\n",
      "1     8\n",
      "2     8\n",
      "3    10\n",
      "4    10\n",
      "Name: text, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# split the text first and then count number of tokens\n",
    "# NOTE that str attribute is called twice\n",
    "print(df['text'].str.split().str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1     True\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "Name: text, dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the text contains 'appointment'\n",
    "df['text'].str.contains('appointment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    4\n",
       "2    3\n",
       "3    4\n",
       "4    8\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count how many times the digits appear in each string\n",
    "df['text'].str.count(r'\\d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   [2, 4, 5]\n",
       "1                [1, 1, 3, 0]\n",
       "2                   [7, 0, 0]\n",
       "3                [1, 1, 1, 5]\n",
       "4    [0, 8, 1, 0, 0, 9, 0, 0]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the digits in each string/row\n",
    "df['text'].str.findall(r'\\d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            [2:45]\n",
      "1           [11:30]\n",
      "2            [7:00]\n",
      "3           [11:15]\n",
      "4    [08:10, 09:00]\n",
      "Name: text, dtype: object\n",
      "0            [2:45]\n",
      "1           [11:30]\n",
      "2            [7:00]\n",
      "3           [11:15]\n",
      "4    [08:10, 09:00]\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# find the group of digits indicating time\n",
    "print(df['text'].str.findall(r'\\d?\\d:\\d\\d'))\n",
    "# or this way\n",
    "print(df['text'].str.findall(r'\\d{1,2}[:]{1}\\d{1,2}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          ???: The doctor's appointment is at 2:45pm.\n",
      "1       ???: The dentist's appointment is at 11:30 am.\n",
      "2          ???: At 7:00pm, there is a basketball game!\n",
      "3         ???: Be back home by 11:15 pm at the latest.\n",
      "4    ???: Take the train at 08:10 am, arrive at 09:...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# replace the week day by ???\n",
    "print(df['text'].str.replace(r'\\w+day', '???'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          Mon: The doctor's appointment is at 2:45pm.\n",
      "1       Tue: The dentist's appointment is at 11:30 am.\n",
      "2          Wed: At 7:00pm, there is a basketball game!\n",
      "3         Thu: Be back home by 11:15 pm at the latest.\n",
      "4    Fri: Take the train at 08:10 am, arrive at 09:...\n",
      "Name: text, dtype: object\n",
      "0          Mon: The doctor's appointment is at 2:45pm.\n",
      "1       Tue: The dentist's appointment is at 11:30 am.\n",
      "2          Wed: At 7:00pm, there is a basketball game!\n",
      "3         Thu: Be back home by 11:15 pm at the latest.\n",
      "4    Fri: Take the train at 08:10 am, arrive at 09:...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# replace weekdays with 3 letter abbrevations\n",
    "# about group/groups method: https://docs.python.org/3/howto/regex.html\n",
    "# simple explanation: first search for string match the pattern r'(\\w+day\\b)'\n",
    "# this returns groups. The first element of groups is the matched pattern (weekday)\n",
    "\n",
    "print(df['text'].str.replace(r'(\\w+day\\b)', lambda x: x.groups()[0][:3]))\n",
    "# or this works the same\n",
    "print(df['text'].str.replace(r'(\\w+day\\b)', lambda x: x.group(0)[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "0   2  45\n",
       "1  11  30\n",
       "2   7  00\n",
       "3  11  15\n",
       "4  08  10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract data ***\n",
    "# df['text'].str.extract(r'\\d{1,2}[:]\\d{1,2}') # doesn't work, we need to put () to make groups?\n",
    "df['text'].str.extract(r'(\\d{1,2})[:](\\d{1,2})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0   1   2\n",
      "  match               \n",
      "0 0       2:45   2  45\n",
      "1 0      11:30  11  30\n",
      "2 0       7:00   7  00\n",
      "3 0      11:15  11  15\n",
      "4 0      08:10  08  10\n",
      "  1      09:00  09  00\n",
      "                0   1   2   3\n",
      "  match                      \n",
      "1 0      11:30 am  11  30  am\n",
      "3 0      11:15 pm  11  15  pm\n",
      "4 0      08:10 am  08  10  am\n",
      "          0   1   2   3\n",
      "0    2:45pm   2  45  pm\n",
      "1  11:30 am  11  30  am\n",
      "2    7:00pm   7  00  pm\n",
      "3  11:15 pm  11  15  pm\n",
      "4  08:10 am  08  10  am\n",
      "                0   1   2   3\n",
      "  match                      \n",
      "0 0        2:45pm   2  45  pm\n",
      "1 0      11:30 am  11  30  am\n",
      "2 0        7:00pm   7  00  pm\n",
      "3 0      11:15 pm  11  15  pm\n",
      "4 0      08:10 am  08  10  am\n",
      "  1       09:00am  09  00  am\n"
     ]
    }
   ],
   "source": [
    "# extractall show all matches found. Extract show only the first match\n",
    "# get hour, minute into 2 separates columns and another column contain boths\n",
    "# note the level of the parenthesis ()\n",
    "print(df['text'].str.extractall(r'((\\d{1,2}):(\\d{1,2}))'))\n",
    "# get also am pm info, what is wrong here without the question mark?\n",
    "# the question mark show unknown number of space? because sometimes am or pm comes without space\n",
    "print(df['text'].str.extractall(r'((\\d{1,2}):(\\d{1,2}) ([ap]m))'))\n",
    "# get also am pm info\n",
    "print(df['text'].str.extract(r'((\\d{1,2}):(\\d{1,2}) ?([ap]m))'))\n",
    "print(df['text'].str.extractall(r'((\\d{1,2}):(\\d{1,2}) ?([ap]m))'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             time hour minute period\n",
      "  match                             \n",
      "0 0        2:45pm    2     45     pm\n",
      "1 0      11:30 am   11     30     am\n",
      "2 0        7:00pm    7     00     pm\n",
      "3 0      11:15 pm   11     15     pm\n",
      "4 0      08:10 am   08     10     am\n",
      "  1       09:00am   09     00     am\n"
     ]
    }
   ],
   "source": [
    "# name group using ?P<name> inside the ()\n",
    "print(df['text'].str.extractall(r'(?P<time>(?P<hour>\\d{1,2}):(?P<minute>\\d{1,2}) ?(?P<period>[ap]m))'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Expressions\n",
    "\n",
    "Regular expressions documentation in Python 3\n",
    "https://docs.python.org/3/library/re.html\n",
    "\n",
    "Tips and tricks of the trade for cleaning text in Python\n",
    "\n",
    "https://stanford.edu/~rjweiss/public_html/IRiSS2013/text2/notebooks/cleaningtext.html\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2014/11/text-data-cleaning-steps-python/\n",
    "\n",
    "http://ieva.rocks/2016/08/07/cleaning-text-for-nlp/\n",
    "\n",
    "https://chrisalbon.com/python/cleaning_text.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
